{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import project directory helper\n",
    "import os, sys\n",
    "ROOT_DIR = os.path.abspath('/home/hduser/document/jupyter/FYP/')\n",
    "BACKEND_DIR = os.path.abspath(\n",
    "    '/home/hduser/document/jupyter/FYP/crawler/backend')\n",
    "sys.path.insert(0, BACKEND_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from consumer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark packages\n",
    "# set the kafka dependencies before create spark context or session\n",
    "# import os\n",
    "# os.environ[\n",
    "#     'PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.4.4,org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4 pyspark-shell'\n",
    "from pyspark.sql import SparkSession, functions, types\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.123.210.3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>attraction</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fea744fc358>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('attraction').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List kafka topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__consumer_offsets\n",
      "testing\n",
      "testing2\n",
      "theculturetrip\n",
      "tripad_activity\n",
      "tripad_attr_activity\n",
      "tripad_attr_location\n",
      "tripad_attr_review\n",
      "tripad_hotel_info\n",
      "tripad_hotel_review\n",
      "tripad_location\n",
      "tripad_review\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "kafka-topics.sh --list --zookeeper 10.123.10.26:2181"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consume theculturetrip data to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dir = '/home/hduser/document/jupyter/FYP/crawler/datasets/theculturetrip_dataset/'\n",
    "broker = ['10.123.10.26:9092']\n",
    "kafka_topic = 'theculturetrip'\n",
    "key = []\n",
    "filepath = ds_dir + kafka_topic + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "kafka_consumer(broker, kafka_topic, filepath, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consume tripad_attr_location data to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dir = '/home/hduser/document/jupyter/FYP/crawler/datasets/tripadvisor_dataset/attractions/'\n",
    "broker = ['10.123.10.26:9092']\n",
    "kafka_topic = 'tripad_attr_location'\n",
    "filepath = ds_dir + kafka_topic + '.json'\n",
    "key = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "kafka_to_json(broker, kafka_topic, filepath, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consume tripad_attr_activity data to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dir = '/home/hduser/document/jupyter/FYP/crawler/datasets/tripadvisor_dataset/attractions/'\n",
    "broker = ['10.123.10.26:9092']\n",
    "kafka_topic = 'tripad_attr_activity'\n",
    "filepath = ds_dir + kafka_topic + '.json'\n",
    "key = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "kafka_to_json(broker, kafka_topic, filepath, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consume tripad_attr_review data to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dir = '/home/hduser/document/jupyter/FYP/crawler/datasets/tripadvisor_dataset/attractions/'\n",
    "broker = ['10.123.10.26:9092']\n",
    "kafka_topic = 'tripad_attr_review'\n",
    "key = [0, 'data', 'locations', 0, 'reviewListPage', 'reviews']\n",
    "filepath = ds_dir + kafka_topic + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "kafka_to_json(broker, kafka_topic, filepath, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consume tripad_hotel_info data to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dir = '/home/hduser/document/jupyter/FYP/crawler/datasets/tripadvisor_dataset/hotels/'\n",
    "broker = ['10.123.10.26:9092']\n",
    "kafka_topic = 'tripad_hotel_info'\n",
    "filepath = ds_dir + kafka_topic + '.json'\n",
    "key = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "kafka_to_json(broker, kafka_topic, filepath, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consume tripad_hotel_review data to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dir = '/home/hduser/document/jupyter/FYP/crawler/datasets/tripadvisor_dataset/hotels/'\n",
    "broker = ['10.123.10.26:9092']\n",
    "kafka_topic = 'tripad_hotel_review'\n",
    "filepath = ds_dir + kafka_topic + '.json'\n",
    "key = [0, 'data', 'locations', 0, 'reviewListPage', 'reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "kafka_to_json(broker, kafka_topic, filepath, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate json data using spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json as spark dataframe\n",
    "spark_df = spark.read.json(ds_dir + kafka_topic + '.json').repartition(160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unwanted columns\n",
    "spark_df = spark_df.drop('__COMMENT')\n",
    "# tripad_attr_review\n",
    "spark_df = spark_df.dropna(subset='__typename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing\n",
    "display(spark_df.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write spark dataframe to parquet\n",
    "spark_df.write.parquet(ds_dir + kafka_topic, mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyspark subscribe kafka topic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  set advertised.listeners=PLAINTEXT://your-kafka-server-ip:9092 in server.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\n",
    "    'PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.4.4,org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions, types\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"attraction\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create streaming contexts\n",
    "# ssc = StreamingContext(spark.sparkContext, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kafkaStream = KafkaUtils.createDirectStream(ssc, ['testing2'], {\n",
    "#     'bootstrap.servers': '10.123.10.26:9092',\n",
    "#     'auto.offset.reset': 'smallest'\n",
    "# })\n",
    "\n",
    "# kafkaStream.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed = kafkaStream.map(lambda x: json.loads(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssc.start()\n",
    "# ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured kafka reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_topic = 'tripad_attr_review'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default for startingOffsets is \"latest\", but \"earliest\" allows rewind for missed data\n",
    "attr_review_kafka_msg = spark.read.format(\"kafka\").option(\n",
    "    \"kafka.bootstrap.servers\",\n",
    "    \"10.123.10.26:9092\").option(\"subscribe\",\n",
    "                                kafka_topic).option(\"startingOffsets\",\n",
    "                                                    \"earliest\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read schema from kafka message value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_msg_df = attr_review_kafka_msg.withColumn(\n",
    "    \"value\", functions.expr(\"string(value)\")).select(\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_msg_df_json = spark.read.json(kafka_msg_df.rdd.map(lambda x: x.value),\n",
    "                                    multiLine=True)\n",
    "kafka_msg_df_json.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_msg_df_json.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required schema\n",
    "# kafka_msg_df_json = kafka_msg_df.select(\n",
    "#     functions.from_json(\n",
    "#         functions.col(\"value\"),\n",
    "#         kafka_msg_df_json.schema).alias(\"data\")).select(\"data.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_spark_df = kafka_msg_df_json.select(\n",
    "    kafka_msg_df_json.data.locations.reviewListPage.reviews.alias(\"reviews\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_spark_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = reviews_spark_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consume kafka data to hbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "broker = ['10.123.10.26:9092']\n",
    "hbase_host = 'localhost'\n",
    "kafka_topic = 'theculturetrip'\n",
    "key = [\"props, pageProps, articleStoreState, articleData, data, link\"]\n",
    "column = [\"m:url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theculturetrip url\n",
    "kafka_to_hbase(broker, hbase_host, kafka_topic, key, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broker = ['10.123.10.26:9092']\n",
    "hbase_host = 'localhost'\n",
    "kafka_topic = 'tripad_attr_location'\n",
    "key = [\"web_url\"]\n",
    "column = [\"m:url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tripadvisor location\n",
    "kafka_to_hbase(broker, hbase_host, kafka_topic, key, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broker = ['10.123.10.26:9092']\n",
    "hbase_host = 'localhost'\n",
    "kafka_topic = 'tripad_attr_activity'\n",
    "key = [\"productHeader\", \"activityId\"]\n",
    "column = [\"m:activityId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tripadvisor activity\n",
    "kafka_to_hbase(broker, hbase_host, kafka_topic, key, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broker = ['10.123.10.26:9092']\n",
    "hbase_host = 'localhost'\n",
    "kafka_topic = 'tripad_attr_review'\n",
    "key = [0, \"data\", \"locations\", 0, \"locationId\"]\n",
    "column = [\"m:locationId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tripadvisor activity review\n",
    "kafka_to_hbase(broker, hbase_host, kafka_topic, key, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
